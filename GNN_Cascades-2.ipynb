{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "931512f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting dgl\n",
      "  Downloading dgl-2.1.0-cp39-cp39-manylinux1_x86_64.whl (8.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx>=2.1 in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from dgl) (2.8.4)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from dgl) (1.10.1)\n",
      "Collecting torchdata>=0.5.0\n",
      "  Downloading torchdata-0.11.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 KB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.8.0 in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from dgl) (5.8.0)\n",
      "Requirement already satisfied: tqdm in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from dgl) (4.65.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from dgl) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from dgl) (1.23.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from requests>=2.19.0->dgl) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from requests>=2.19.0->dgl) (2022.12.7)\n",
      "Requirement already satisfied: charset_normalizer~=2.0.0 in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from requests>=2.19.0->dgl) (2.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from requests>=2.19.0->dgl) (3.2)\n",
      "Collecting torch>=2\n",
      "  Downloading torch-2.6.0-cp39-cp39-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions>=4.10.0\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 KB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.4.127\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.1.2)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (2022.11.0)\n",
      "Collecting nvidia-nccl-cu12==2.21.5\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==3.2.0\n",
      "  Downloading triton-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from torch>=2->torchdata>=0.5.0->dgl) (3.12.0)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 KB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sympy==1.13.1\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from sympy==1.13.1->torch>=2->torchdata>=0.5.0->dgl) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from jinja2->torch>=2->torchdata>=0.5.0->dgl) (2.1.2)\n",
      "Installing collected packages: triton, nvidia-cusparselt-cu12, typing-extensions, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchdata, dgl\n",
      "\u001b[33m  WARNING: The scripts proton and proton-viewer are installed in '/eos/user/h/hsharma/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script isympy is installed in '/eos/user/h/hsharma/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[33m  WARNING: The scripts torchfrtrace and torchrun are installed in '/eos/user/h/hsharma/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "zfit 0.20.3 requires colorama, which is not installed.\n",
      "zfit 0.20.3 requires colored, which is not installed.\n",
      "zfit 0.20.3 requires frozendict, which is not installed.\n",
      "zfit 0.20.3 requires jacobi, which is not installed.\n",
      "zfit 0.20.3 requires numdifftools, which is not installed.\n",
      "zfit 0.20.3 requires ordered-set, which is not installed.\n",
      "zfit 0.20.3 requires texttable, which is not installed.\n",
      "zfit 0.20.3 requires zfit-interface, which is not installed.\n",
      "tensorflow 2.12.0 requires gast<=0.4.0,>=0.2.1, but you have gast 0.5.2 which is incompatible.\n",
      "zfit 0.20.3 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.12.0 which is incompatible.\n",
      "ydata-profiling 4.6.5 requires pydantic>=2, but you have pydantic 1.10.9 which is incompatible.\n",
      "ydata-profiling 4.6.5 requires typeguard<5,>=4.1.2, but you have typeguard 2.13.3 which is incompatible.\n",
      "tf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.12.0 which is incompatible.\n",
      "onnxconverter-common 1.14.0 requires protobuf==3.20.2, but you have protobuf 3.20.3 which is incompatible.\n",
      "hipe4ml 0.0.16 requires ipython>=7.32.0, but you have ipython 7.25.0 which is incompatible.\n",
      "hipe4ml-converter 0.0.6 requires jedi==0.17.2, but you have jedi 0.18.0 which is incompatible.\n",
      "chex 0.1.87 requires jax>=0.4.27, but you have jax 0.4.8 which is incompatible.\n",
      "chex 0.1.87 requires jaxlib>=0.4.27, but you have jaxlib 0.4.7 which is incompatible.\n",
      "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dgl-2.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.6.0 torchdata-0.11.0 triton-3.2.0 typing-extensions-4.12.2\n"
     ]
    }
   ],
   "source": [
    "!pip install dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31f7a33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting dgl==0.6.1\n",
      "  Downloading dgl-0.6.1-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from dgl==0.6.1) (1.10.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from dgl==0.6.1) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from dgl==0.6.1) (1.23.5)\n",
      "Requirement already satisfied: networkx>=2.1 in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from dgl==0.6.1) (2.8.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from requests>=2.19.0->dgl==0.6.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from requests>=2.19.0->dgl==0.6.1) (2022.12.7)\n",
      "Requirement already satisfied: charset_normalizer~=2.0.0 in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from requests>=2.19.0->dgl==0.6.1) (2.0.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /cvmfs/sft.cern.ch/lcg/views/LCG_104a_cuda/x86_64-centos7-gcc11-opt/lib/python3.9/site-packages (from requests>=2.19.0->dgl==0.6.1) (3.2)\n",
      "Installing collected packages: dgl\n",
      "  Attempting uninstall: dgl\n",
      "    Found existing installation: dgl 2.1.0\n",
      "    Uninstalling dgl-2.1.0:\n",
      "      Successfully uninstalled dgl-2.1.0\n",
      "Successfully installed dgl-0.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install dgl==0.6.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de38da99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.10835482180118561\n",
      "Epoch 10, Loss: 0.009253941476345062\n",
      "Epoch 20, Loss: 0.00033967450144700706\n",
      "Epoch 30, Loss: 0.0002434186899336055\n",
      "Epoch 40, Loss: 0.000351965194568038\n",
      "Epoch 50, Loss: 0.00016729801427572966\n",
      "Epoch 60, Loss: 5.0019931222777814e-05\n",
      "Epoch 70, Loss: 6.189429768710397e-06\n",
      "Epoch 80, Loss: 5.479332116919977e-07\n",
      "Epoch 90, Loss: 3.4585034427436767e-06\n",
      "Epoch 100, Loss: 1.1046533927583368e-06\n",
      "Epoch 110, Loss: 4.5870777398704377e-08\n",
      "Epoch 120, Loss: 1.936658975409955e-07\n",
      "Epoch 130, Loss: 1.649159836469849e-10\n",
      "Epoch 140, Loss: 2.0266165634552635e-08\n",
      "Epoch 150, Loss: 4.368715167402115e-09\n",
      "Epoch 160, Loss: 6.482093334314598e-11\n",
      "Epoch 170, Loss: 4.58307475303954e-10\n",
      "Epoch 180, Loss: 3.3410191280225376e-10\n",
      "Epoch 190, Loss: 1.412569089476179e-10\n",
      "Epoch 200, Loss: 6.003335328852444e-11\n",
      "Epoch 210, Loss: 2.702847667901409e-11\n",
      "Epoch 220, Loss: 7.759628009584851e-12\n",
      "Epoch 230, Loss: 1.7313311157993172e-12\n",
      "Epoch 240, Loss: 1.3239741334519772e-12\n",
      "Epoch 250, Loss: 1.4377007613933235e-12\n",
      "Epoch 260, Loss: 1.3274870569110475e-12\n",
      "Epoch 270, Loss: 8.438497838859915e-13\n",
      "Epoch 280, Loss: 1.3371816674767611e-12\n",
      "Epoch 290, Loss: 8.989196648330477e-13\n",
      "Epoch 300, Loss: 8.772509628440783e-13\n",
      "Epoch 310, Loss: 8.349502187733615e-13\n",
      "Epoch 320, Loss: 8.32689982504381e-13\n",
      "Epoch 330, Loss: 8.465441347048352e-13\n",
      "Epoch 340, Loss: 8.197978971016817e-13\n",
      "Epoch 350, Loss: 8.112621360280292e-13\n",
      "Epoch 360, Loss: 8.280579455628712e-13\n",
      "Epoch 370, Loss: 8.275946659745681e-13\n",
      "Epoch 380, Loss: 8.27888864234072e-13\n",
      "Epoch 390, Loss: 8.327738455424227e-13\n",
      "Epoch 400, Loss: 8.285084315655389e-13\n",
      "Epoch 410, Loss: 8.251482721925718e-13\n",
      "Epoch 420, Loss: 8.444046785578696e-13\n",
      "Epoch 430, Loss: 8.183753696412721e-13\n",
      "Epoch 440, Loss: 8.43984767056466e-13\n",
      "Epoch 450, Loss: 8.360423356217062e-13\n",
      "Epoch 460, Loss: 8.819220852739063e-13\n",
      "Epoch 470, Loss: 8.890182427029325e-13\n",
      "Epoch 480, Loss: 8.099163700814316e-13\n",
      "Epoch 490, Loss: 8.563858715053552e-13\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import uproot\n",
    "\n",
    "# Load data\n",
    "file = uproot.open(\"/eos/user/h/hsharma/PythiaFIles/Cascades_Xi/cascade_data.root\")\n",
    "tree = file[\"cascade_tree\"]\n",
    "data = tree.arrays(library=\"ak\")\n",
    "data = data[:5000]\n",
    "\n",
    "# Extract relevant features\n",
    "px = ak.to_numpy(data[\"px\"])\n",
    "py = ak.to_numpy(data[\"py\"])\n",
    "pz = ak.to_numpy(data[\"pz\"])\n",
    "charge = ak.to_numpy(data[\"charge\"])\n",
    "\n",
    "# Create a node feature matrix\n",
    "node_features = np.column_stack((px, py, pz, charge))\n",
    "\n",
    "# Number of nodes\n",
    "num_nodes = node_features.shape[0]\n",
    "\n",
    "# Create an edge list for a fully connected graph\n",
    "edges = np.array([[i, j] for i in range(num_nodes) for j in range(num_nodes) if i != j]).T\n",
    "\n",
    "# Convert edge index to PyTorch tensor\n",
    "edge_index_tensor = torch.tensor(edges, dtype=torch.long)\n",
    "\n",
    "# Ensure undirected edges\n",
    "edge_index_tensor = torch.cat([edge_index_tensor, edge_index_tensor.flip(0)], dim=1)\n",
    "\n",
    "# Convert node features to tensor\n",
    "node_features_tensor = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "# Ensure everything is on the same device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create PyG Data object\n",
    "graph_data = Data(x=node_features_tensor, edge_index=edge_index_tensor).to(device)\n",
    "\n",
    "# Define the GNN model\n",
    "class GNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "        self.fc = nn.Linear(output_dim, 1)  # Regression output (single value per node)\n",
    "        self.output_layer = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#     def forward(self, data):\n",
    "#         x = self.conv1(data.x, data.edge_index)\n",
    "#         x = torch.relu(x)\n",
    "#         x = self.conv2(x, data.edge_index)\n",
    "#         x = self.output_layer(x)  # Linear layer\n",
    "#         x = self.sigmoid(x)  # Apply sigmoid here\n",
    "#         return x\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Define model, optimizer, and loss function\n",
    "model = GNN(input_dim=4, hidden_dim=64, output_dim=32).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "loss_fn = nn.MSELoss()\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Generate synthetic target values (for example purposes)\n",
    "# Ideally, you should use actual data labels instead of ones.\n",
    "target_values = torch.ones((num_nodes, 1), dtype=torch.float, device=device)\n",
    "\n",
    "# Training function\n",
    "def train(model, data, optimizer, loss_fn, epochs=500):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "\n",
    "        # Ensure output and target have the same shape\n",
    "        loss = loss_fn(out, target_values)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "# Run training\n",
    "train(model, graph_data, optimizer, loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6714960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Fixed edge index for val_data!\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a dataset `data` and want to split it\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create a mask for training and validation sets (80% training, 20% validation)\n",
    "train_mask, val_mask = train_test_split(range(node_features.shape[0]), test_size=0.2)\n",
    "\n",
    "# Create training and validation data objects\n",
    "train_data = Data(x=node_features_tensor[train_mask], edge_index=edge_index_tensor[:, train_mask])\n",
    "val_data = Data(x=node_features_tensor[val_mask], edge_index=edge_index_tensor[:, val_mask])\n",
    "\n",
    "# Ensure the data is on the same device as the model\n",
    "train_data = train_data.to(device)\n",
    "val_data = val_data.to(device)\n",
    "\n",
    "num_val_nodes = val_data.x.shape[0]  # Should be 200\n",
    "\n",
    "# Create a fully connected edge index for 200 nodes\n",
    "edge_index_val = torch.tensor(\n",
    "    [[i, j] for i in range(num_val_nodes) for j in range(num_val_nodes) if i != j], dtype=torch.long\n",
    ").T\n",
    "\n",
    "# Update val_data\n",
    "val_data.edge_index = edge_index_val.to(device)\n",
    "\n",
    "print(\"✅ Fixed edge index for val_data!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "902641a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw model output (first 10 values): [5.462045 5.462045 5.462045 5.462045 5.462045 5.462045 5.462045 5.462045\n",
      " 5.462045 5.462045]\n",
      "Validation Loss: 19.909849166870117\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, val_data, loss_fn):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(val_data)\n",
    "        print(f\"Raw model output (first 10 values): {out[:10].cpu().numpy().flatten()}\")  # Debugging\n",
    "\n",
    "        target = torch.ones_like(out).to(out.device)  \n",
    "        loss = loss_fn(out, target)\n",
    "        print(f\"Validation Loss: {loss.item()}\")\n",
    "\n",
    "        return out, loss.item()\n",
    "\n",
    "# # Evaluate the model on the validation set\n",
    "predictions, val_loss = evaluate(model, val_data, loss_fn)\n",
    "\n",
    "# Check if the indices in edge_index are valid\n",
    "# num_nodes = val_data.x.size(0)\n",
    "# assert (val_data.edge_index.min() >= 0).item(), \"Edge index contains negative values.\"\n",
    "# assert (val_data.edge_index.max() < num_nodes).item(), f\"Edge index contains out-of-bounds values (max: {val_data.edge_index.max()}, num_nodes: {num_nodes}).\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f40764f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Ensure predictions is a PyTorch tensor before creating the target tensor\n",
    "if not isinstance(predictions, torch.Tensor):\n",
    "    predictions_tensor = torch.tensor(predictions, dtype=torch.float32, device=device)\n",
    "else:\n",
    "    predictions_tensor = predictions  # Already a tensor\n",
    "\n",
    "# Create the target tensor before conversion\n",
    "targets_tensor = torch.ones_like(predictions_tensor)\n",
    "\n",
    "# Convert both to NumPy\n",
    "predictions = predictions_tensor.cpu().numpy().flatten()\n",
    "targets = targets_tensor.cpu().numpy().flatten()\n",
    "\n",
    "# Plot\n",
    "plt.scatter(range(len(predictions)), predictions, label=\"Predictions\", alpha=0.6)\n",
    "plt.scatter(range(len(targets)), targets, label=\"Targets\", alpha=0.6)\n",
    "plt.xlabel(\"Node Index\")\n",
    "plt.ylabel(\"Predicted Value\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
